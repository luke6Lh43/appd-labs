---
# Source: opentelemetry-demo/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: opentelemetry-demo
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0  
    opentelemetry.io/name: opentelemetry-demo
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/name: opentelemetry-demo
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-adservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: adservice
    app.kubernetes.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: opentelemetry-demo-adservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-cartservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0   
    opentelemetry.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: cartservice
    app.kubernetes.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:    
    opentelemetry.io/name: opentelemetry-demo-cartservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-checkoutservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: checkoutservice
    app.kubernetes.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector: 
    opentelemetry.io/name: opentelemetry-demo-checkoutservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-currencyservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: currencyservice
    app.kubernetes.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: opentelemetry-demo-currencyservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-emailservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: emailservice
    app.kubernetes.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: opentelemetry-demo-emailservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-featureflagservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: featureflagservice
    app.kubernetes.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 50053
      name: grpc
      targetPort: 50053
    - port: 8081
      name: http
      targetPort: 8081
  selector: 
    opentelemetry.io/name: opentelemetry-demo-featureflagservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-ffspostgres
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: ffspostgres
    app.kubernetes.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 5432
      name: postgres
      targetPort: 5432
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-ffspostgres
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-frontend
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-frontend
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-frontendproxy
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-frontendproxy
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontendproxy
    app.kubernetes.io/name: opentelemetry-demo-frontendproxy
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-frontendproxy
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-kafka
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0  
    opentelemetry.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 9092
      name: plaintext
      targetPort: 9092
    - port: 9093
      name: controller
      targetPort: 9093
  selector:
    opentelemetry.io/name: opentelemetry-demo-kafka
---
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-kafka-exporter
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0  
    opentelemetry.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
  annotations:
    appdynamics.com/exporter_type: "kafka"
    # When multiple OTel demo instances are being monitored by the same CNAO instance, below value should be unique to have each kafka cluster monitored seperately
    appdynamics.com/kafka_cluster_name: "opentelemetry-demo-kafka-cluster"
    prometheus.io/path: "/metrics"
    prometheus.io/port: "9308"
spec:
  type: ClusterIP
  ports:
  - port: 9308
    protocol: TCP
    targetPort: 9308
  selector:
    opentelemetry.io/name: opentelemetry-demo-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-loadgenerator
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: loadgenerator
    app.kubernetes.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8089
      name: tcp-service
      targetPort: 8089
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-loadgenerator
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-paymentservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: paymentservice
    app.kubernetes.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-paymentservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-productcatalogservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: productcatalogservice
    app.kubernetes.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-productcatalogservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-quoteservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: quoteservice
    app.kubernetes.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-quoteservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-recommendationservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: recommendationservice
    app.kubernetes.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    
    opentelemetry.io/name: opentelemetry-demo-recommendationservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-redis
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-redis
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: redis2
    app.kubernetes.io/name: opentelemetry-demo-redis
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 6379
      name: redis
      targetPort: 6379
  selector: 
    opentelemetry.io/name: opentelemetry-demo-redis
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-redis-exporter
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-redis
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: redis2
    app.kubernetes.io/name: opentelemetry-demo-redis
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
  annotations:
    appdynamics.com/exporter_type: "redis"
    prometheus.io/path: "/metrics"
    prometheus.io/port: "9121"
spec:
  type: ClusterIP
  ports:
    - port: 9121
      protocol: TCP
      targetPort: 9121
  selector: 
    opentelemetry.io/name: opentelemetry-demo-redis
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: v1
kind: Service
metadata:
  name: opentelemetry-demo-shippingservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: shippingservice
    app.kubernetes.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8080
      name: tcp-service
      targetPort: 8080
  selector:
    opentelemetry.io/name: opentelemetry-demo-shippingservice
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-accountingservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-accountingservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: accountingservice
    app.kubernetes.io/name: opentelemetry-demo-accountingservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-accountingservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-accountingservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: accountingservice
        app.kubernetes.io/name: opentelemetry-demo-accountingservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: accountingservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-accountingservice'
          imagePullPolicy: IfNotPresent
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: KAFKA_SERVICE_ADDR
            value: 'opentelemetry-demo-kafka:9092'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 20Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && ./accountingservice']
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-kafka 9092; do echo waiting
            for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-adservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0  
    opentelemetry.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: adservice
    app.kubernetes.io/name: opentelemetry-demo-adservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-adservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-adservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: adservice
        app.kubernetes.io/name: opentelemetry-demo-adservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: adservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-adservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: AD_SERVICE_PORT
            value: "8080"
          - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
            value: 'opentelemetry-demo-featureflagservice:50053'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTLP_LOGS_EXPORTER
            value: otlp
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 300Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && ./build/install/opentelemetry-demo-ad-service/bin/AdService']
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-cartservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: cartservice
    app.kubernetes.io/name: opentelemetry-demo-cartservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-cartservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-cartservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: cartservice
        app.kubernetes.io/name: opentelemetry-demo-cartservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: cartservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-cartservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: CART_SERVICE_PORT
            value: "8080"
          - name: ASPNETCORE_URLS
            value: http://*:$(CART_SERVICE_PORT)
          - name: REDIS_ADDR
            value: 'opentelemetry-demo-redis:6379'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 160Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && ./cartservice']
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-redis 6379; do echo waiting
            for redis; sleep 2; done;
          image: busybox:latest
          name: wait-for-redis
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-checkoutservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: checkoutservice
    app.kubernetes.io/name: opentelemetry-demo-checkoutservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-checkoutservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-checkoutservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: checkoutservice
        app.kubernetes.io/name: opentelemetry-demo-checkoutservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: checkoutservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-checkoutservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: CHECKOUT_SERVICE_PORT
            value: "8080"
          - name: CART_SERVICE_ADDR
            value: 'opentelemetry-demo-cartservice:8080'
          - name: CURRENCY_SERVICE_ADDR
            value: 'opentelemetry-demo-currencyservice:8080'
          - name: EMAIL_SERVICE_ADDR
            value: http://opentelemetry-demo-emailservice:8080
          - name: PAYMENT_SERVICE_ADDR
            value: 'opentelemetry-demo-paymentservice:8080'
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: 'opentelemetry-demo-productcatalogservice:8080'
          - name: SHIPPING_SERVICE_ADDR
            value: 'opentelemetry-demo-shippingservice:8080'
          - name: KAFKA_SERVICE_ADDR
            value: 'opentelemetry-demo-kafka:9092'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 20Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && ./checkoutservice'] 
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-kafka 9092; do echo waiting
            for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-currencyservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: currencyservice
    app.kubernetes.io/name: opentelemetry-demo-currencyservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-currencyservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-currencyservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: currencyservice
        app.kubernetes.io/name: opentelemetry-demo-currencyservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: currencyservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-currencyservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: CURRENCY_SERVICE_PORT
            value: "8080"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 20Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && ./currencyservice ${CURRENCY_SERVICE_PORT}'] 
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-emailservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: emailservice
    app.kubernetes.io/name: opentelemetry-demo-emailservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-emailservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-emailservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: emailservice
        app.kubernetes.io/name: opentelemetry-demo-emailservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: emailservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-emailservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: EMAIL_SERVICE_PORT
            value: "8080"
          - name: APP_ENV
            value: production
          - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 100Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && bundle exec ruby email_server.rb']
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-featureflagservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: featureflagservice
    app.kubernetes.io/name: opentelemetry-demo-featureflagservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-featureflagservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-featureflagservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: featureflagservice
        app.kubernetes.io/name: opentelemetry-demo-featureflagservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: featureflagservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-featureflagservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 50053
            name: grpc
          - containerPort: 8081
            name: http
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: FEATURE_FLAG_SERVICE_PORT
            value: "8081"
          - name: FEATURE_FLAG_GRPC_SERVICE_PORT
            value: "50053"
          - name: DATABASE_URL
            value: ecto://ffs:ffs@opentelemetry-demo-ffspostgres:5432/ffs
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_EXPORTER_OTLP_TRACES_PROTOCOL
            value: grpc
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 175Mi
          livenessProbe:
            httpGet:
              path: /featureflags/
              port: 8081
            initialDelaySeconds: 30
            periodSeconds: 10
          # command: ["/bin/sh"]
          # args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && /app/bin/server'] 
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-ffspostgres 5432; do echo
            waiting for ffspostgres; sleep 2; done
          image: busybox:latest
          name: wait-for-ffspostgres
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-ffspostgres
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: ffspostgres
    app.kubernetes.io/name: opentelemetry-demo-ffspostgres
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-ffspostgres
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-ffspostgres
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: ffspostgres
        app.kubernetes.io/name: opentelemetry-demo-ffspostgres
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: ffspostgres
          image: 'postgres:14'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 5432
            name: postgres
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: POSTGRES_DB
            value: ffs
          - name: POSTGRES_USER
            value: ffs
          - name: POSTGRES_PASSWORD
            value: ffs
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 120Mi
          securityContext:
            runAsGroup: 999
            runAsNonRoot: true
            runAsUser: 999
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && docker-entrypoint.sh postgres'] 
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-frauddetectionservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-frauddetectionservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frauddetectionservice
    app.kubernetes.io/name: opentelemetry-demo-frauddetectionservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-frauddetectionservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-frauddetectionservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: frauddetectionservice
        app.kubernetes.io/name: opentelemetry-demo-frauddetectionservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frauddetectionservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-frauddetectionservice'
          imagePullPolicy: IfNotPresent
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: KAFKA_SERVICE_ADDR
            value: 'opentelemetry-demo-kafka:9092'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 200Mi
          args: ['/bin/sh', '-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && java -jar frauddetectionservice-1.0-all.jar']
      initContainers:
        - command:
          - sh
          - -c
          - until nc -z -v -w30 opentelemetry-demo-kafka 9092; do echo waiting
            for kafka; sleep 2; done;
          image: busybox:latest
          name: wait-for-kafka
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-frontend
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontend
    app.kubernetes.io/name: opentelemetry-demo-frontend
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-frontend
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-frontend
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: frontend
        app.kubernetes.io/name: opentelemetry-demo-frontend
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frontend
          image: 'ghcr.io/open-telemetry/demo:1.4.0-frontend'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: FRONTEND_PORT
            value: "8080"
          - name: FRONTEND_ADDR
            value: :8080
          - name: AD_SERVICE_ADDR
            value: 'opentelemetry-demo-adservice:8080'
          - name: CART_SERVICE_ADDR
            value: 'opentelemetry-demo-cartservice:8080'
          - name: CHECKOUT_SERVICE_ADDR
            value: 'opentelemetry-demo-checkoutservice:8080'
          - name: CURRENCY_SERVICE_ADDR
            value: 'opentelemetry-demo-currencyservice:8080'
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: 'opentelemetry-demo-productcatalogservice:8080'
          - name: RECOMMENDATION_SERVICE_ADDR
            value: 'opentelemetry-demo-recommendationservice:8080'
          - name: SHIPPING_SERVICE_ADDR
            value: 'opentelemetry-demo-shippingservice:8080'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: WEB_OTEL_SERVICE_NAME
            value: frontend-web
          - name: PUBLIC_OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://localhost:4318/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 200Mi
          securityContext:
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && npm start'] 
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-frontendproxy
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-frontendproxy
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: frontendproxy
    app.kubernetes.io/name: opentelemetry-demo-frontendproxy
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-frontendproxy
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-frontendproxy
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: frontendproxy
        app.kubernetes.io/name: opentelemetry-demo-frontendproxy
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: frontendproxy
          image: 'ghcr.io/open-telemetry/demo:1.4.0-frontendproxy'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: ENVOY_PORT
            value: "8080"
          - name: FRONTEND_PORT
            value: "8080"
          - name: FRONTEND_HOST
            value: 'opentelemetry-demo-frontend'
          - name: FEATURE_FLAG_SERVICE_PORT
            value: "8081"
          - name: FEATURE_FLAG_SERVICE_HOST
            value: 'opentelemetry-demo-featureflagservice'
          - name: LOCUST_WEB_PORT
            value: "8089"
          - name: LOCUST_WEB_HOST
            value: 'opentelemetry-demo-loadgenerator'
          - name: GRAFANA_SERVICE_PORT
            value: "80"
          - name: GRAFANA_SERVICE_HOST
            value: 'opentelemetry-demo-grafana'
          - name: JAEGER_SERVICE_PORT
            value: "16686"
          - name: JAEGER_SERVICE_HOST
            value: 'opentelemetry-demo-jaeger-query'
          - name: OTEL_COLLECTOR_PORT
            value: "4317"
          - name: OTEL_COLLECTOR_HOST
            value: $(OTEL_COLLECTOR_NAME)
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 50Mi
          securityContext:
            runAsGroup: 101
            runAsNonRoot: true
            runAsUser: 101
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && envsubst < envoy.tmpl.yaml > envoy.yaml && envoy -c envoy.yaml'] 
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-kafka
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: kafka
    app.kubernetes.io/name: opentelemetry-demo-kafka
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:     
      opentelemetry.io/name: opentelemetry-demo-kafka
  template:
    metadata:
      labels:
        opentelemetry.io/name: opentelemetry-demo-kafka
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: kafka
        app.kubernetes.io/name: opentelemetry-demo-kafka
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - image: danielqsj/kafka-exporter:latest
          name: kafka-exporter
          args: ["--kafka.server", "opentelemetry-demo-kafka:9092"]
          ports:
          - containerPort: 9308
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
        - name: kafka
          image: 'ghcr.io/open-telemetry/demo:1.4.0-kafka'
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 9092
            name: plaintext
          - containerPort: 9093
            name: controller
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: KAFKA_ADVERTISED_LISTENERS
            value: PLAINTEXT://opentelemetry-demo-kafka:9092
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: KAFKA_HEAP_OPTS
            value: -Xmx200M -Xms200M
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 500Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && /tmp/update_run.sh && /etc/confluent/docker/run'] 
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-loadgenerator
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: loadgenerator
    app.kubernetes.io/name: opentelemetry-demo-loadgenerator
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-loadgenerator
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-loadgenerator
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: loadgenerator
        app.kubernetes.io/name: opentelemetry-demo-loadgenerator
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: loadgenerator
          image: 'ghcr.io/open-telemetry/demo:1.4.0-loadgenerator'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8089
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: LOCUST_WEB_PORT
            value: "8089"
          - name: LOCUST_USERS
            value: "10"
          - name: LOCUST_SPAWN_RATE
            value: "1"
          - name: LOCUST_HOST
            value: http://opentelemetry-demo-frontend:8080
          - name: LOCUST_HEADLESS
            value: "false"
          - name: LOCUST_AUTOSTART
            value: "true"
          - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
            value: python
          - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 120Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && locust'] 
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-paymentservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: paymentservice
    app.kubernetes.io/name: opentelemetry-demo-paymentservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-paymentservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-paymentservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: paymentservice
        app.kubernetes.io/name: opentelemetry-demo-paymentservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: paymentservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-paymentservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: PAYMENT_SERVICE_PORT
            value: "8080"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 120Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && npm run start']
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-productcatalogservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: productcatalogservice
    app.kubernetes.io/name: opentelemetry-demo-productcatalogservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-productcatalogservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-productcatalogservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: productcatalogservice
        app.kubernetes.io/name: opentelemetry-demo-productcatalogservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: productcatalogservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-productcatalogservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: PRODUCT_CATALOG_SERVICE_PORT
            value: "8080"
          - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
            value: 'opentelemetry-demo-featureflagservice:50053'
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 20Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && ./productcatalogservice']
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-quoteservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: quoteservice
    app.kubernetes.io/name: opentelemetry-demo-quoteservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-quoteservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-quoteservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: quoteservice
        app.kubernetes.io/name: opentelemetry-demo-quoteservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: quoteservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-quoteservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: QUOTE_SERVICE_PORT
            value: "8080"
          - name: OTEL_PHP_AUTOLOAD_ENABLED
            value: "true"
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4318
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 40Mi
          securityContext:
            runAsGroup: 33
            runAsNonRoot: true
            runAsUser: 33
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && php public/index.php']
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-recommendationservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: recommendationservice
    app.kubernetes.io/name: opentelemetry-demo-recommendationservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-recommendationservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-recommendationservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: recommendationservice
        app.kubernetes.io/name: opentelemetry-demo-recommendationservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: recommendationservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-recommendationservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: RECOMMENDATION_SERVICE_PORT
            value: "8080"
          - name: PRODUCT_CATALOG_SERVICE_ADDR
            value: 'opentelemetry-demo-productcatalogservice:8080'
          - name: FEATURE_FLAG_GRPC_SERVICE_ADDR
            value: 'opentelemetry-demo-featureflagservice:50053'
          - name: OTEL_PYTHON_LOG_CORRELATION
            value: "true"
          - name: PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION
            value: python
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 500Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && opentelemetry-instrument python recommendation_server.py']
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-redis
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    opentelemetry.io/name: opentelemetry-demo-redis
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: redis2
    app.kubernetes.io/name: opentelemetry-demo-redis
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      opentelemetry.io/name: opentelemetry-demo-redis
  template:
    metadata:
      labels:
        opentelemetry.io/name: opentelemetry-demo-redis
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: redis2
        app.kubernetes.io/name: opentelemetry-demo-redis
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - image: oliver006/redis_exporter:latest
          name: redis-exporter
          args: ["--redis.addr", "redis://opentelemetry-demo-redis:6379"]
          ports:
          - containerPort: 9121
          resources:
            requests:
              cpu: 100m
              memory: 100Mi
          securityContext:
            runAsUser: 59000
            runAsGroup: 59000
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
        - name: redis
          image: 'redis:alpine'
          imagePullPolicy: IfNotPresent
          ports:
          - containerPort: 6379
            name: redis
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 20Mi
          securityContext:
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 999
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && docker-entrypoint.sh redis-server']
---
# Source: opentelemetry-demo/templates/component.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: opentelemetry-demo-shippingservice
  labels:
    helm.sh/chart: opentelemetry-demo-0.22.0
    
    opentelemetry.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/instance: opentelemetry-demo
    app.kubernetes.io/component: shippingservice
    app.kubernetes.io/name: opentelemetry-demo-shippingservice
    app.kubernetes.io/version: "1.4.0"
    app.kubernetes.io/part-of: opentelemetry-demo
    app.kubernetes.io/managed-by: Helm
spec:
  selector:
    matchLabels:
      
      opentelemetry.io/name: opentelemetry-demo-shippingservice
  template:
    metadata:
      labels:
        
        opentelemetry.io/name: opentelemetry-demo-shippingservice
        app.kubernetes.io/instance: opentelemetry-demo
        app.kubernetes.io/component: shippingservice
        app.kubernetes.io/name: opentelemetry-demo-shippingservice
    spec:
      serviceAccountName: opentelemetry-demo
      containers:
        - name: shippingservice
          image: 'ghcr.io/open-telemetry/demo:1.4.0-shippingservice'
          imagePullPolicy: IfNotPresent
          ports:
          
          - containerPort: 8080
            name: service
          env:
          - name: OTEL_SERVICE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.labels['app.kubernetes.io/component']
          - name: OTEL_K8S_NAMESPACE
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.namespace
          - name: OTEL_K8S_NODE_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: spec.nodeName
          - name: OTEL_K8S_POD_NAME
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.name
          - name: OTEL_K8S_POD_UID
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: metadata.uid
          - name: OTEL_COLLECTOR_NAME
            value: appdynamics-otel-collector-service.appdynamics.svc.cluster.local
          - name: SHIPPING_SERVICE_PORT
            value: "8080"
          - name: QUOTE_SERVICE_ADDR
            value: http://opentelemetry-demo-quoteservice:8080
          - name: OTEL_EXPORTER_OTLP_TRACES_ENDPOINT
            value: http://$(OTEL_COLLECTOR_NAME):4317/v1/traces
          - name: OTEL_RESOURCE_ATTRIBUTES
            value: service.name=$(OTEL_SERVICE_NAME),service.namespace=$(OTEL_K8S_NAMESPACE),k8s.namespace.name=$(OTEL_K8S_NAMESPACE),k8s.node.name=$(OTEL_K8S_NODE_NAME),k8s.pod.name=$(OTEL_K8S_POD_NAME)
          resources:
            limits:
              memory: 20Mi
          command: ["/bin/sh"]
          args: ['-c', 'OTEL_RESOURCE_ATTRIBUTES=$OTEL_RESOURCE_ATTRIBUTES,container.id=$(sed -rn "s/^.+\/.+\/.+\/.+\/cri-containerd-(.+).scope \/sys\/fs\/cgroup\/devices.+$/\1/p" /proc/self/mountinfo) && /app/shippingservice']